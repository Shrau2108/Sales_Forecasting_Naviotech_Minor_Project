{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc902aa4-a57c-4877-a201-d07f5b5d427f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙ FEATURE ENGINEERING NOTEBOOK\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Cleaned CSV in data/processed/ (e.g. cleaned_train.csv):  adani_monthly_cleaned.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\lalee\\\\Downloads\\\\Mini_Project_Shravani_Harel_Sales_Forecasting\\\\data\\\\processed\\\\adani_monthly_cleaned.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m csv_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleaned CSV in data/processed/ (e.g. cleaned_train.csv): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     15\u001b[0m clean_path \u001b[38;5;241m=\u001b[39m DATA_PROCESSED_DIR \u001b[38;5;241m/\u001b[39m csv_name\n\u001b[1;32m---> 17\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(clean_path)\n\u001b[0;32m     18\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Infer columns again just to be safe\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\lalee\\\\Downloads\\\\Mini_Project_Shravani_Harel_Sales_Forecasting\\\\data\\\\processed\\\\adani_monthly_cleaned.csv'"
     ]
    }
   ],
   "source": [
    "# 02_feature_engineering.ipynb\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "import pandas as pd\n",
    "from src.data_prep import build_daily_series\n",
    "from src.feature_engineering import build_feature_frame\n",
    "from src.config import DATA_PROCESSED_DIR, DATA_FEATURE_DIR\n",
    "\n",
    "print(\"⚙ FEATURE ENGINEERING NOTEBOOK\")\n",
    "\n",
    "csv_name = input(\"Cleaned CSV in data/processed/ (e.g. cleaned_train.csv): \").strip()\n",
    "clean_path = DATA_PROCESSED_DIR / csv_name\n",
    "\n",
    "df = pd.read_csv(clean_path)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Infer columns again just to be safe\n",
    "from src.data_prep import _detect_date_column, _detect_target_column   # if you kept them private, expose wrappers\n",
    "date_col = _detect_date_column(df)\n",
    "target_col = _detect_target_column(df, date_col)\n",
    "\n",
    "ts = build_daily_series(df, date_col, target_col)\n",
    "data, feature_cols = build_feature_frame(ts)\n",
    "\n",
    "print(\"\\n✅ Feature frame created\")\n",
    "print(\"Feature columns:\", feature_cols)\n",
    "\n",
    "out_path = DATA_FEATURE_DIR / \"final_training_dataset.csv\"\n",
    "print(f\"Saved → {out_path}\")\n",
    "data.to_csv(out_path, index=False)\n",
    "display(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e970cb0-7573-4c2b-a061-69838e75e043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select target from: ['monthly_sales']\n",
      "Feature dataset saved ✔\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>monthly_sales</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_14</th>\n",
       "      <th>lag_30</th>\n",
       "      <th>roll_7</th>\n",
       "      <th>roll_30</th>\n",
       "      <th>volatility</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-01</th>\n",
       "      <td>1.035674e+12</td>\n",
       "      <td>1.035802e+12</td>\n",
       "      <td>1.035941e+12</td>\n",
       "      <td>1.036636e+12</td>\n",
       "      <td>1.037608e+12</td>\n",
       "      <td>1.039832e+12</td>\n",
       "      <td>1.036081e+12</td>\n",
       "      <td>1.037678e+12</td>\n",
       "      <td>2.976247e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-02</th>\n",
       "      <td>1.035546e+12</td>\n",
       "      <td>1.035674e+12</td>\n",
       "      <td>1.035802e+12</td>\n",
       "      <td>1.036497e+12</td>\n",
       "      <td>1.037469e+12</td>\n",
       "      <td>1.039693e+12</td>\n",
       "      <td>1.035946e+12</td>\n",
       "      <td>1.037540e+12</td>\n",
       "      <td>2.933712e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-03</th>\n",
       "      <td>1.035418e+12</td>\n",
       "      <td>1.035546e+12</td>\n",
       "      <td>1.035674e+12</td>\n",
       "      <td>1.036358e+12</td>\n",
       "      <td>1.037330e+12</td>\n",
       "      <td>1.039554e+12</td>\n",
       "      <td>1.035811e+12</td>\n",
       "      <td>1.037402e+12</td>\n",
       "      <td>2.882453e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-04</th>\n",
       "      <td>1.035290e+12</td>\n",
       "      <td>1.035418e+12</td>\n",
       "      <td>1.035546e+12</td>\n",
       "      <td>1.036219e+12</td>\n",
       "      <td>1.037191e+12</td>\n",
       "      <td>1.039415e+12</td>\n",
       "      <td>1.035679e+12</td>\n",
       "      <td>1.037265e+12</td>\n",
       "      <td>2.830889e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-05</th>\n",
       "      <td>1.035163e+12</td>\n",
       "      <td>1.035290e+12</td>\n",
       "      <td>1.035418e+12</td>\n",
       "      <td>1.036080e+12</td>\n",
       "      <td>1.037052e+12</td>\n",
       "      <td>1.039276e+12</td>\n",
       "      <td>1.035548e+12</td>\n",
       "      <td>1.037127e+12</td>\n",
       "      <td>2.787717e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            monthly_sales         lag_1         lag_2         lag_7  \\\n",
       "date                                                                  \n",
       "2016-03-01   1.035674e+12  1.035802e+12  1.035941e+12  1.036636e+12   \n",
       "2016-03-02   1.035546e+12  1.035674e+12  1.035802e+12  1.036497e+12   \n",
       "2016-03-03   1.035418e+12  1.035546e+12  1.035674e+12  1.036358e+12   \n",
       "2016-03-04   1.035290e+12  1.035418e+12  1.035546e+12  1.036219e+12   \n",
       "2016-03-05   1.035163e+12  1.035290e+12  1.035418e+12  1.036080e+12   \n",
       "\n",
       "                  lag_14        lag_30        roll_7       roll_30  \\\n",
       "date                                                                 \n",
       "2016-03-01  1.037608e+12  1.039832e+12  1.036081e+12  1.037678e+12   \n",
       "2016-03-02  1.037469e+12  1.039693e+12  1.035946e+12  1.037540e+12   \n",
       "2016-03-03  1.037330e+12  1.039554e+12  1.035811e+12  1.037402e+12   \n",
       "2016-03-04  1.037191e+12  1.039415e+12  1.035679e+12  1.037265e+12   \n",
       "2016-03-05  1.037052e+12  1.039276e+12  1.035548e+12  1.037127e+12   \n",
       "\n",
       "              volatility  \n",
       "date                      \n",
       "2016-03-01  2.976247e+08  \n",
       "2016-03-02  2.933712e+08  \n",
       "2016-03-03  2.882453e+08  \n",
       "2016-03-04  2.830889e+08  \n",
       "2016-03-05  2.787717e+08  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/cleaned/adani_monthly_cleaned.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "date_col = [c for c in df.columns if \"date\" in c.lower()][0]\n",
    "df[date_col] = pd.to_datetime(df[date_col])\n",
    "df = df.sort_values(date_col)\n",
    "\n",
    "# Select Target (you choose later)\n",
    "TARGET = \"Auto_Select\"    # placeholder\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['float','int']).columns.tolist()\n",
    "numeric_cols.remove(\"Date\") if \"Date\" in numeric_cols else None\n",
    "\n",
    "print(\"Select target from:\", numeric_cols)\n",
    "\n",
    "# Convert to time-series\n",
    "ts = df[[date_col, numeric_cols[0]]]   # editable later\n",
    "ts.set_index(date_col, inplace=True)\n",
    "ts = ts.asfreq(\"D\").interpolate()\n",
    "\n",
    "# Generate Lag Features\n",
    "for lag in [1, 2, 7, 14, 30]:\n",
    "    ts[f\"lag_{lag}\"] = ts[numeric_cols[0]].shift(lag)\n",
    "\n",
    "# Rolling Signals\n",
    "ts[\"roll_7\"]  = ts[numeric_cols[0]].rolling(7).mean()\n",
    "ts[\"roll_30\"] = ts[numeric_cols[0]].rolling(30).mean()\n",
    "ts[\"volatility\"] = ts[numeric_cols[0]].rolling(7).std()\n",
    "\n",
    "ts = ts.dropna()\n",
    "ts.to_csv(\"../data/features/feature_engineered.csv\")\n",
    "\n",
    "print(\"Feature dataset saved ✔\")\n",
    "ts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a91c39-dc2f-49cb-85b1-68528b754675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_prep import load_and_clean_csv,build_daily_series\n",
    "from src.feature_engineering import build_feature_frame\n",
    "\n",
    "file=input(\"cleaned file in data/processed/: \")\n",
    "df,date,target=load_and_clean_csv(f\"data/processed/{file}\")\n",
    "ts=build_daily_series(df,date,target)\n",
    "final,_=build_feature_frame(ts)\n",
    "final.to_csv(\"data/features/final_training_dataset.csv\",index=False)\n",
    "final.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
